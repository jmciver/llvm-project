// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -no-opaque-pointers -flax-vector-conversions=none -ffreestanding -triple x86_64-gnu-linux -target-feature +avx512f -O0 -enable-noundef-load-analysis -emit-llvm -o - %s | FileCheck %s
// RUN: %clang_cc1 -no-opaque-pointers -flax-vector-conversions=none -ffreestanding -triple x86_64-gnu-linux -target-feature +avx512f -O0 -no-enable-noundef-load-analysis -emit-llvm -o - %s | FileCheck %s --check-prefix=DISABLE

#include <immintrin.h>

// CHECK-LABEL: @test_mm_mask_div_ss(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[__A_ADDR_I:%.*]] = alloca <4 x float>, align 16
// CHECK-NEXT:    [[__B_ADDR_I:%.*]] = alloca <4 x float>, align 16
// CHECK-NEXT:    [[__W_ADDR_I:%.*]] = alloca <4 x float>, align 16
// CHECK-NEXT:    [[__U_ADDR_I:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[__A_ADDR_I2:%.*]] = alloca <4 x float>, align 16
// CHECK-NEXT:    [[__B_ADDR_I2:%.*]] = alloca <4 x float>, align 16
// CHECK-NEXT:    [[__W_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-NEXT:    [[__U_ADDR:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[__A_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-NEXT:    [[__B_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-NEXT:    store <4 x float> [[__W:%.*]], <4 x float>* [[__W_ADDR]], align 16
// CHECK-NEXT:    store i8 [[__U:%.*]], i8* [[__U_ADDR]], align 1
// CHECK-NEXT:    store <4 x float> [[__A:%.*]], <4 x float>* [[__A_ADDR]], align 16
// CHECK-NEXT:    store <4 x float> [[__B:%.*]], <4 x float>* [[__B_ADDR]], align 16
// CHECK-NEXT:    [[TMP0:%.*]] = load <4 x float>, <4 x float>* [[__W_ADDR]], align 16, !noundef [[NOUNDEF2:![0-9]+]]
// CHECK-NEXT:    [[TMP1:%.*]] = load i8, i8* [[__U_ADDR]], align 1
// CHECK-NEXT:    [[TMP2:%.*]] = load <4 x float>, <4 x float>* [[__A_ADDR]], align 16, !noundef [[NOUNDEF2]]
// CHECK-NEXT:    [[TMP3:%.*]] = load <4 x float>, <4 x float>* [[__B_ADDR]], align 16, !noundef [[NOUNDEF2]]
// CHECK-NEXT:    store <4 x float> [[TMP0]], <4 x float>* [[__W_ADDR_I]], align 16
// CHECK-NEXT:    store i8 [[TMP1]], i8* [[__U_ADDR_I]], align 1
// CHECK-NEXT:    store <4 x float> [[TMP2]], <4 x float>* [[__A_ADDR_I2]], align 16
// CHECK-NEXT:    store <4 x float> [[TMP3]], <4 x float>* [[__B_ADDR_I2]], align 16
// CHECK-NEXT:    [[TMP4:%.*]] = load <4 x float>, <4 x float>* [[__A_ADDR_I2]], align 16, !noundef [[NOUNDEF2]]
// CHECK-NEXT:    [[TMP5:%.*]] = load <4 x float>, <4 x float>* [[__B_ADDR_I2]], align 16, !noundef [[NOUNDEF2]]
// CHECK-NEXT:    store <4 x float> [[TMP4]], <4 x float>* [[__A_ADDR_I]], align 16
// CHECK-NEXT:    store <4 x float> [[TMP5]], <4 x float>* [[__B_ADDR_I]], align 16
// CHECK-NEXT:    [[TMP6:%.*]] = load <4 x float>, <4 x float>* [[__B_ADDR_I]], align 16, !noundef [[NOUNDEF2]]
// CHECK-NEXT:    [[VECEXT_I:%.*]] = extractelement <4 x float> [[TMP6]], i32 0
// CHECK-NEXT:    [[TMP7:%.*]] = load <4 x float>, <4 x float>* [[__A_ADDR_I]], align 16, !noundef [[NOUNDEF2]]
// CHECK-NEXT:    [[VECEXT1_I:%.*]] = extractelement <4 x float> [[TMP7]], i32 0
// CHECK-NEXT:    [[DIV_I:%.*]] = fdiv float [[VECEXT1_I]], [[VECEXT_I]]
// CHECK-NEXT:    [[TMP8:%.*]] = load <4 x float>, <4 x float>* [[__A_ADDR_I]], align 16, !noundef [[NOUNDEF2]]
// CHECK-NEXT:    [[VECINS_I:%.*]] = insertelement <4 x float> [[TMP8]], float [[DIV_I]], i32 0
// CHECK-NEXT:    store <4 x float> [[VECINS_I]], <4 x float>* [[__A_ADDR_I]], align 16
// CHECK-NEXT:    [[TMP9:%.*]] = load <4 x float>, <4 x float>* [[__A_ADDR_I]], align 16, !noundef [[NOUNDEF2]]
// CHECK-NEXT:    store <4 x float> [[TMP9]], <4 x float>* [[__A_ADDR_I2]], align 16
// CHECK-NEXT:    [[TMP10:%.*]] = load i8, i8* [[__U_ADDR_I]], align 1
// CHECK-NEXT:    [[TMP11:%.*]] = load <4 x float>, <4 x float>* [[__A_ADDR_I2]], align 16, !noundef [[NOUNDEF2]]
// CHECK-NEXT:    [[TMP12:%.*]] = load <4 x float>, <4 x float>* [[__W_ADDR_I]], align 16, !noundef [[NOUNDEF2]]
// CHECK-NEXT:    [[TMP13:%.*]] = extractelement <4 x float> [[TMP11]], i64 0
// CHECK-NEXT:    [[TMP14:%.*]] = extractelement <4 x float> [[TMP12]], i64 0
// CHECK-NEXT:    [[TMP15:%.*]] = bitcast i8 [[TMP10]] to <8 x i1>
// CHECK-NEXT:    [[TMP16:%.*]] = extractelement <8 x i1> [[TMP15]], i64 0
// CHECK-NEXT:    [[TMP17:%.*]] = select i1 [[TMP16]], float [[TMP13]], float [[TMP14]]
// CHECK-NEXT:    [[TMP18:%.*]] = insertelement <4 x float> [[TMP11]], float [[TMP17]], i64 0
// CHECK-NEXT:    ret <4 x float> [[TMP18]]
//
// DISABLE-LABEL: @test_mm_mask_div_ss(
// DISABLE-NEXT:  entry:
// DISABLE-NEXT:    [[__A_ADDR_I:%.*]] = alloca <4 x float>, align 16
// DISABLE-NEXT:    [[__B_ADDR_I:%.*]] = alloca <4 x float>, align 16
// DISABLE-NEXT:    [[__W_ADDR_I:%.*]] = alloca <4 x float>, align 16
// DISABLE-NEXT:    [[__U_ADDR_I:%.*]] = alloca i8, align 1
// DISABLE-NEXT:    [[__A_ADDR_I2:%.*]] = alloca <4 x float>, align 16
// DISABLE-NEXT:    [[__B_ADDR_I2:%.*]] = alloca <4 x float>, align 16
// DISABLE-NEXT:    [[__W_ADDR:%.*]] = alloca <4 x float>, align 16
// DISABLE-NEXT:    [[__U_ADDR:%.*]] = alloca i8, align 1
// DISABLE-NEXT:    [[__A_ADDR:%.*]] = alloca <4 x float>, align 16
// DISABLE-NEXT:    [[__B_ADDR:%.*]] = alloca <4 x float>, align 16
// DISABLE-NEXT:    store <4 x float> [[__W:%.*]], <4 x float>* [[__W_ADDR]], align 16
// DISABLE-NEXT:    store i8 [[__U:%.*]], i8* [[__U_ADDR]], align 1
// DISABLE-NEXT:    store <4 x float> [[__A:%.*]], <4 x float>* [[__A_ADDR]], align 16
// DISABLE-NEXT:    store <4 x float> [[__B:%.*]], <4 x float>* [[__B_ADDR]], align 16
// DISABLE-NEXT:    [[TMP0:%.*]] = load <4 x float>, <4 x float>* [[__W_ADDR]], align 16
// DISABLE-NEXT:    [[TMP1:%.*]] = load i8, i8* [[__U_ADDR]], align 1
// DISABLE-NEXT:    [[TMP2:%.*]] = load <4 x float>, <4 x float>* [[__A_ADDR]], align 16
// DISABLE-NEXT:    [[TMP3:%.*]] = load <4 x float>, <4 x float>* [[__B_ADDR]], align 16
// DISABLE-NEXT:    store <4 x float> [[TMP0]], <4 x float>* [[__W_ADDR_I]], align 16
// DISABLE-NEXT:    store i8 [[TMP1]], i8* [[__U_ADDR_I]], align 1
// DISABLE-NEXT:    store <4 x float> [[TMP2]], <4 x float>* [[__A_ADDR_I2]], align 16
// DISABLE-NEXT:    store <4 x float> [[TMP3]], <4 x float>* [[__B_ADDR_I2]], align 16
// DISABLE-NEXT:    [[TMP4:%.*]] = load <4 x float>, <4 x float>* [[__A_ADDR_I2]], align 16
// DISABLE-NEXT:    [[TMP5:%.*]] = load <4 x float>, <4 x float>* [[__B_ADDR_I2]], align 16
// DISABLE-NEXT:    store <4 x float> [[TMP4]], <4 x float>* [[__A_ADDR_I]], align 16
// DISABLE-NEXT:    store <4 x float> [[TMP5]], <4 x float>* [[__B_ADDR_I]], align 16
// DISABLE-NEXT:    [[TMP6:%.*]] = load <4 x float>, <4 x float>* [[__B_ADDR_I]], align 16
// DISABLE-NEXT:    [[VECEXT_I:%.*]] = extractelement <4 x float> [[TMP6]], i32 0
// DISABLE-NEXT:    [[TMP7:%.*]] = load <4 x float>, <4 x float>* [[__A_ADDR_I]], align 16
// DISABLE-NEXT:    [[VECEXT1_I:%.*]] = extractelement <4 x float> [[TMP7]], i32 0
// DISABLE-NEXT:    [[DIV_I:%.*]] = fdiv float [[VECEXT1_I]], [[VECEXT_I]]
// DISABLE-NEXT:    [[TMP8:%.*]] = load <4 x float>, <4 x float>* [[__A_ADDR_I]], align 16
// DISABLE-NEXT:    [[VECINS_I:%.*]] = insertelement <4 x float> [[TMP8]], float [[DIV_I]], i32 0
// DISABLE-NEXT:    store <4 x float> [[VECINS_I]], <4 x float>* [[__A_ADDR_I]], align 16
// DISABLE-NEXT:    [[TMP9:%.*]] = load <4 x float>, <4 x float>* [[__A_ADDR_I]], align 16
// DISABLE-NEXT:    store <4 x float> [[TMP9]], <4 x float>* [[__A_ADDR_I2]], align 16
// DISABLE-NEXT:    [[TMP10:%.*]] = load i8, i8* [[__U_ADDR_I]], align 1
// DISABLE-NEXT:    [[TMP11:%.*]] = load <4 x float>, <4 x float>* [[__A_ADDR_I2]], align 16
// DISABLE-NEXT:    [[TMP12:%.*]] = load <4 x float>, <4 x float>* [[__W_ADDR_I]], align 16
// DISABLE-NEXT:    [[TMP13:%.*]] = extractelement <4 x float> [[TMP11]], i64 0
// DISABLE-NEXT:    [[TMP14:%.*]] = extractelement <4 x float> [[TMP12]], i64 0
// DISABLE-NEXT:    [[TMP15:%.*]] = bitcast i8 [[TMP10]] to <8 x i1>
// DISABLE-NEXT:    [[TMP16:%.*]] = extractelement <8 x i1> [[TMP15]], i64 0
// DISABLE-NEXT:    [[TMP17:%.*]] = select i1 [[TMP16]], float [[TMP13]], float [[TMP14]]
// DISABLE-NEXT:    [[TMP18:%.*]] = insertelement <4 x float> [[TMP11]], float [[TMP17]], i64 0
// DISABLE-NEXT:    ret <4 x float> [[TMP18]]
//
__m128 test_mm_mask_div_ss(__m128 __W, __mmask8 __U, __m128 __A, __m128 __B) {
  return _mm_mask_div_ss(__W,__U,__A,__B);
}
